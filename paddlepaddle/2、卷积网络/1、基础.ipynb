{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 基础\n",
    "\n",
    "全连接网络对图片的特征提取的问题（将一张图片上的所有像素点展开成一个1维向量输入网络）：\n",
    "\n",
    "![20221128160037](https://cdn.jsdelivr.net/gh/xihuishawpy/PicBad@main/blogs/pictures/20221128160037.png)\n",
    "\n",
    "在卷积神经网络中，计算范围是在像素点的空间邻域内进行的，卷积核参数的数目也远小于全连接层。卷积核本身与输入图片大小无关，它代表了对空间邻域内某种特征模式的提取。\n",
    "\n",
    "卷积中，输入与输出的维度计算：(p为padding填充大小，k为kernel卷积核大小，s为stride步幅大小)\n",
    "\n",
    "![20221128161140](https://cdn.jsdelivr.net/gh/xihuishawpy/PicBad@main/blogs/pictures/20221128161140.png)\n",
    "\n",
    "比如，输入的图片大小为 28 * 28 ， kernel_size=5, stride=1, padding=2 ， 输出大小为 (28+2 * 2-5) / 1 +1 = 28 ， 与输入图片大小保持一致。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 多通道、批量操作\n",
    "\n",
    "多输入通道：\n",
    "\n",
    "![20221128162327](https://cdn.jsdelivr.net/gh/xihuishawpy/PicBad@main/blogs/pictures/20221128162327.png)\n",
    "\n",
    "多输出通道：\n",
    "\n",
    "![20221128162432](https://cdn.jsdelivr.net/gh/xihuishawpy/PicBad@main/blogs/pictures/20221128162432.png)\n",
    "\n",
    "批量操作：\n",
    "\n",
    "![20221128162657](https://cdn.jsdelivr.net/gh/xihuishawpy/PicBad@main/blogs/pictures/20221128162657.png)\n",
    "\n",
    "\n",
    "![20221128163552](https://cdn.jsdelivr.net/gh/xihuishawpy/PicBad@main/blogs/pictures/20221128163552.png)\n",
    "\n",
    "## 池化、relu激活函数、Batch Normalization、Drop out\n",
    "\n",
    "![20221129155413](https://cdn.jsdelivr.net/gh/xihuishawpy/PicBad@main/blogs/pictures/20221129155413.png)\n",
    "\n",
    "![20221129161313](https://cdn.jsdelivr.net/gh/xihuishawpy/PicBad@main/blogs/pictures/20221129161313.png)\n",
    "\n",
    "![20221129161125](https://cdn.jsdelivr.net/gh/xihuishawpy/PicBad@main/blogs/pictures/20221129161125.png)\n",
    "\n",
    "![20221129161417](https://cdn.jsdelivr.net/gh/xihuishawpy/PicBad@main/blogs/pictures/20221129161417.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output of BatchNorm1D Layer: \n",
      " [[-1.2247438 -1.2247438 -1.2247438]\n",
      " [ 0.         0.         0.       ]\n",
      " [ 1.2247438  1.2247438  1.2247438]]\n",
      "std 4.0, mean 2.449489742783178, \n",
      " output [-1.22474487  0.          1.22474487]\n"
     ]
    }
   ],
   "source": [
    "# 输入数据形状是 [N, K]时的示例\n",
    "\n",
    "import numpy as np\n",
    "import paddle\n",
    "from paddle.nn import BatchNorm1D\n",
    "\n",
    "\n",
    "data = np.array([[1,2,3], [4,5,6], [7,8,9]]).astype('float32')\n",
    "\n",
    "# 使用BatchNorm1D计算归一化的输出\n",
    "# 输入数据维度[N, K]，num_features等于K\n",
    "bn = BatchNorm1D(num_features=3)    \n",
    "x = paddle.to_tensor(data)\n",
    "y = bn(x)\n",
    "print('output of BatchNorm1D Layer: \\n {}'.format(y.numpy()))\n",
    "\n",
    "# 使用Numpy计算均值、方差和归一化的输出\n",
    "# 这里对第0个特征进行验证\n",
    "a = np.array([1,4,7])\n",
    "a_mean = a.mean()\n",
    "a_std = a.std()\n",
    "b = (a - a_mean) / a_std\n",
    "print('std {}, mean {}, \\n output {}'.format(a_mean, a_std, b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "当输入数据形状是[N,C,H,W]时， 一般对应卷积层的输出。这种情况下`会沿着C这一维度进行展开`，分别`对每一个通道计算N个样本`中总共N×H×W个像素点的均值和方差"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input of BatchNorm2D Layer: \n",
      " [[[[0.54340494 0.2783694  0.4245176 ]\n",
      "   [0.84477615 0.00471886 0.12156912]\n",
      "   [0.67074907 0.82585275 0.13670659]]\n",
      "\n",
      "  [[0.5750933  0.89132196 0.20920213]\n",
      "   [0.18532822 0.10837689 0.21969749]\n",
      "   [0.9786238  0.8116832  0.17194101]]\n",
      "\n",
      "  [[0.81622475 0.27407375 0.4317042 ]\n",
      "   [0.9400298  0.81764936 0.33611196]\n",
      "   [0.17541045 0.37283206 0.00568851]]]\n",
      "\n",
      "\n",
      " [[[0.25242636 0.7956625  0.01525497]\n",
      "   [0.5988434  0.6038045  0.10514768]\n",
      "   [0.38194343 0.03647606 0.89041156]]\n",
      "\n",
      "  [[0.98092085 0.05994199 0.89054596]\n",
      "   [0.5769015  0.7424797  0.63018394]\n",
      "   [0.5818422  0.02043913 0.21002658]]\n",
      "\n",
      "  [[0.5446849  0.76911515 0.25069523]\n",
      "   [0.2858957  0.8523951  0.9750065 ]\n",
      "   [0.8848533  0.35950786 0.59885895]]]]\n",
      "output of BatchNorm2D Layer: \n",
      " [[[[ 0.4126078  -0.46198368  0.02029109]\n",
      "   [ 1.4071034  -1.3650038  -0.97940934]\n",
      "   [ 0.832831    1.344658   -0.9294571 ]]\n",
      "\n",
      "  [[ 0.2520175   1.2038351  -0.84927964]\n",
      "   [-0.9211378  -1.1527538  -0.8176896 ]\n",
      "   [ 1.4666051   0.96413004 -0.961432  ]]\n",
      "\n",
      "  [[ 0.9541142  -0.9075856  -0.36629617]\n",
      "   [ 1.37925     0.9590063  -0.6945517 ]\n",
      "   [-1.2463869  -0.5684581  -1.8291974 ]]]\n",
      "\n",
      "\n",
      " [[[-0.5475932   1.2450331  -1.3302356 ]\n",
      "   [ 0.5955492   0.6119205  -1.0335984 ]\n",
      "   [-0.12019944 -1.2602081   1.5576957 ]]\n",
      "\n",
      "  [[ 1.473519   -1.2985382   1.2014993 ]\n",
      "   [ 0.25745988  0.7558342   0.41783488]\n",
      "   [ 0.27233088 -1.4174379  -0.8467981 ]]\n",
      "\n",
      "  [[ 0.02166975  0.79234385 -0.98786545]\n",
      "   [-0.86699003  1.0783203   1.4993572 ]\n",
      "   [ 1.1897788  -0.6142123   0.20769882]]]]\n",
      "channel 0 of input data: \n",
      " [[[0.54340494 0.2783694  0.4245176 ]\n",
      "  [0.84477615 0.00471886 0.12156912]\n",
      "  [0.67074907 0.82585275 0.13670659]]\n",
      "\n",
      " [[0.25242636 0.7956625  0.01525497]\n",
      "  [0.5988434  0.6038045  0.10514768]\n",
      "  [0.38194343 0.03647606 0.89041156]]]\n",
      "std 0.4183686077594757, mean 0.3030227720737457, \n",
      " output: \n",
      " [[[ 0.41263014 -0.46200886  0.02029219]\n",
      "  [ 1.4071798  -1.3650781  -0.9794626 ]\n",
      "  [ 0.8328762   1.3447311  -0.92950773]]\n",
      "\n",
      " [[-0.54762304  1.2451009  -1.3303081 ]\n",
      "  [ 0.5955816   0.61195374 -1.0336547 ]\n",
      "  [-0.12020606 -1.2602768   1.5577804 ]]]\n"
     ]
    }
   ],
   "source": [
    "# 输入数据形状是[N, C, H, W]时的batchnorm示例\n",
    "\n",
    "import numpy as np\n",
    "import paddle\n",
    "from paddle.nn import BatchNorm2D\n",
    "\n",
    "\n",
    "np.random.seed(100)\n",
    "data = np.random.rand(2,3,3,3).astype('float32')\n",
    "\n",
    "# 使用BatchNorm2D计算归一化的输出\n",
    "# 输入数据维度[N, C, H, W]，num_features等于C\n",
    "bn = BatchNorm2D(num_features=3)\n",
    "x = paddle.to_tensor(data)\n",
    "y = bn(x)\n",
    "print('input of BatchNorm2D Layer: \\n {}'.format(x.numpy()))\n",
    "print('output of BatchNorm2D Layer: \\n {}'.format(y.numpy()))\n",
    "\n",
    "# 取出data中第0通道的数据，\n",
    "# 使用numpy计算均值、方差及归一化的输出\n",
    "a = data[:, 0, :, :]\n",
    "a_mean = a.mean()\n",
    "a_std = a.std()\n",
    "b = (a - a_mean) / a_std\n",
    "print('channel 0 of input data: \\n {}'.format(a))\n",
    "print('std {}, mean {}, \\n output: \\n {}'.format(a_mean, a_std, b))\n",
    "\n",
    "# 提示：这里通过numpy计算出来的输出\n",
    "# 与BatchNorm2D算子的结果略有差别，\n",
    "# 因为在BatchNorm2D算子为了保证数值的稳定性，\n",
    "# 在分母里面加上了一个比较小的浮点数epsilon=1e-05"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.15 ('paddle')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "dc03531e3015553affe1fa0734fdd021a885eb8a88bb99dabf4a3c95a410d7e6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
