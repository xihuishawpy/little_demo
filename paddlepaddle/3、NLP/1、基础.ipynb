{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![20221212170259](https://cdn.jsdelivr.net/gh/xihuishawpy/PicBad@main/blogs/pictures/20221212170259.png)\n",
    "\n",
    "## 词向量 Word Embedding\n",
    "\n",
    "把每个词都表示为N维空间里的点，即高维空间的向量，在一定意义上可以代表这个词的语义信息；向量之间的距离，代表词语间的关联关系。\n",
    "\n",
    "![20221212171109](https://cdn.jsdelivr.net/gh/xihuishawpy/PicBad@main/blogs/pictures/20221212171109.png)\n",
    "\n",
    "## word2vec\n",
    "\n",
    "![20221212171525](https://cdn.jsdelivr.net/gh/xihuishawpy/PicBad@main/blogs/pictures/20221212171525.png)\n",
    "\n",
    "![20221212171833](https://cdn.jsdelivr.net/gh/xihuishawpy/PicBad@main/blogs/pictures/20221212171833.png)\n",
    "\n",
    "一般来说，CBOW比Skip-gram训练速度快，训练过程更加稳定：CBOW使用上下文average的方式进行训练，每个训练step会见到更多样本。\n",
    "\n",
    "在生僻字（出现频率低的字）处理上，skip-gram比CBOW效果更好：skip-gram不会刻意回避生僻字(CBOW结构中输入中存在生僻字时，生僻字会被其它非生僻字的权重冲淡)。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CROW\n",
    "\n",
    "输入4个词（4*5000的one-hot向量)\n",
    "\n",
    "![20221212174648](https://cdn.jsdelivr.net/gh/xihuishawpy/PicBad@main/blogs/pictures/20221212174648.png)\n",
    "\n",
    "\n",
    "![20221212174747](https://cdn.jsdelivr.net/gh/xihuishawpy/PicBad@main/blogs/pictures/20221212174747.png)\n",
    "\n",
    "### skip-gram\n",
    "\n",
    "![20221212175448](https://cdn.jsdelivr.net/gh/xihuishawpy/PicBad@main/blogs/pictures/20221212175448.png)\n",
    "\n",
    "![20221212175530](https://cdn.jsdelivr.net/gh/xihuishawpy/PicBad@main/blogs/pictures/20221212175530.png)\n",
    "\n",
    "> 在实际操作中，使用一个滑动窗口（一般情况下，长度是奇数），从左到右开始扫描当前句子。每个扫描出来的片段被当成一个小句子，每个小句子中间的词被认为是中心词，其余的词被认为是这个中心词的上下文。"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
