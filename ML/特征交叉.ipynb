{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 类别特征和连续性特征 一阶交叉\n",
    "\n",
    "def cross_cat_num(df, num_col, cat_col):\n",
    "    for f1 in tqdm(cat_col):\n",
    "        g = df.groupby(f1, as_index=False)\n",
    "        for f2 in tqdm(num_col):\n",
    "            feat = g[f2].agg({\n",
    "                '{}_{}_max'.format(f1, f2): 'max', '{}_{}_min'.format(f1, f2): 'min',\n",
    "                '{}_{}_median'.format(f1, f2): 'median',\n",
    "            })\n",
    "            df = df.merge(feat, on=f1, how='left')\n",
    "    return (df)\n",
    "\n",
    "data = cross_cat_num(data, num_col, cat_col)  # 一阶交叉\n",
    "print('一阶交叉特征处理后：', data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count 编码\n",
    "def count_coding(df, col_cat):\n",
    "    for f in col_cat:\n",
    "        df[f'{f}_count'] = df[f].map(df[f].value_counts())\n",
    "    return (df)\n",
    "\n",
    "data = count_coding(data,col_cat)\n",
    "\n",
    "\n",
    "# 类别特征二阶交叉\n",
    "f_pairs = [['是否双频','信用等级代码'],['婚姻状况','预计收入'],['婚姻状况','信用等级代码'],['家庭成人人数','家庭中唯一订阅者的数量'],['信息库匹配','账户消费限额'],\n",
    "           ['信用等级代码','信息库匹配'],['地理区域','家庭活跃用户数'],['家庭活跃用户数','信用等级代码'],['是否翻新机','家庭中唯一订阅者的数量']]\n",
    "\n",
    "def cross_qua_cat_num(df):\n",
    "    for f_pair in tqdm(f_pairs):\n",
    "        ### 共现次数\n",
    "        df['_'.join(f_pair) + '_count'] = df.groupby(f_pair)['客户ID'].transform('count')\n",
    "        ### n unique、熵\n",
    "        df = df.merge(df.groupby(f_pair[0], as_index=False)[f_pair[1]].agg({\n",
    "            '{}_{}_nunique'.format(f_pair[0], f_pair[1]): 'nunique',\n",
    "            '{}_{}_ent'.format(f_pair[0], f_pair[1]): lambda x: entropy(x.value_counts() / x.shape[0])\n",
    "        }), on=f_pair[0], how='left')\n",
    "        df = df.merge(df.groupby(f_pair[1], as_index=False)[f_pair[0]].agg({\n",
    "            '{}_{}_nunique'.format(f_pair[1], f_pair[0]): 'nunique',\n",
    "            '{}_{}_ent'.format(f_pair[1], f_pair[0]): lambda x: entropy(x.value_counts() / x.shape[0])\n",
    "        }), on=f_pair[1], how='left')\n",
    "        ### 比例偏好\n",
    "        df['{}_in_{}_prop'.format(f_pair[0], f_pair[1])] = df['_'.join(f_pair) + '_count'] / df[f_pair[1] + '_count']\n",
    "        df['{}_in_{}_prop'.format(f_pair[1], f_pair[0])] = df['_'.join(f_pair) + '_count'] / df[f_pair[0] + '_count']\n",
    "    return (df)\n",
    "\n",
    "\n",
    "cross_qua_cat_num(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 类别特征 -- 单个、组合count\n",
    "\n",
    "# count_combinations = [\n",
    "#         ['app'],\n",
    "#         ['ip'],  # 3.03\n",
    "#         ['ip', 'device'],  # 9.88\n",
    "#         ['day', 'hour', 'app'],  # 4.08\n",
    "#         ['app', 'channel'],  # 2.8\n",
    "#         ['ip', 'day', 'in_test_hh'],  # 1.74\n",
    "#         ['ip', 'day', 'hour'],  # 0.52\n",
    "#         ['os', 'device'],  # 0.44\n",
    "#         ['ip', 'os', 'day', 'hour'],  # 0.41\n",
    "#     ]\n",
    "\n",
    "\n",
    "def count_agg(df, group_cols):\n",
    "    for i, cols in enumerate(group_cols):\n",
    "        col_name = \"_\".join(cols) + '_count'\n",
    "        print(i, col_name)\n",
    "        count = df.groupby(cols).size().reset_index(name=col_name)\n",
    "        df = df.merge(count, on=cols, how='left')\n",
    "        del count\n",
    "        gc.collect()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 类别特征--累计count\n",
    "\n",
    "# accum_combinations = [\n",
    "#     # ['app'],\n",
    "#     ['ip']  # 3.03\n",
    "#     # ['day', 'hour', 'app']\n",
    "# ]\n",
    "\n",
    "def count_cum(df, group_cols):\n",
    "    for i, cols in enumerate(group_cols):\n",
    "        col_name = \"_\".join(cols) + '_countAccum'\n",
    "        print(i, col_name)\n",
    "        df[col_name] = df.groupby(cols).cumcount()\n",
    "        gc.collect()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 类别特征 -- 组合特征 col_nuique\n",
    "\n",
    "# countUniq_combinations = [\n",
    "#         # [['app'],'ip'],\n",
    "#         # [['app', 'device', 'os', 'channel'], 'ip'],\n",
    "#         [['ip'], 'channel'],  # 0.9\n",
    "#         [['ip'], 'app'],  # 1.3\n",
    "#         [['ip'], 'os']  # 0.45\n",
    "#     ]\n",
    "\n",
    "def count_uniq(df, group_uniq_cols):\n",
    "    for i, cols in enumerate(group_uniq_cols):\n",
    "        group_cols, uniq_col = cols[0], cols[1]\n",
    "        col_name = \"_\".join(group_cols) + '_uniq_' + uniq_col + '_countUniq'\n",
    "        print(i, col_name)\n",
    "        tmp = df.groupby(group_cols)[uniq_col].nunique().reset_index(name=col_name)\n",
    "        df = df.merge(tmp, on=group_cols, how='left')\n",
    "        del tmp\n",
    "        gc.collect()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 时序特征 -- 不同类别特征组合下的shift时间差\n",
    "\n",
    "# nextClick_combinations = [\n",
    "#         ['ip', 'os'],\n",
    "#         ['ip', 'device', 'os'],\n",
    "#         ['ip', 'app', 'device', 'os'],\n",
    "#         ['ip', 'app', 'device', 'os', 'channel']\n",
    "#     ]\n",
    "\n",
    "def next_click(df, group_cols):\n",
    "    for i, cols in enumerate(group_cols):\n",
    "        col_name = \"_\".join(cols) + '_nextClick'\n",
    "        print(i, col_name)\n",
    "        df[col_name] = (df.groupby(cols).click_time.shift(-1) - df.click_time).astype(np.float32)\n",
    "        gc.collect()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 类别特征 -- 类别特征分组 统计连续值\n",
    "\n",
    "# combination_col_mean = [\n",
    "#         [['ip','os'], 'values'],  # 0.9\n",
    "#     ]\n",
    "\n",
    "def frequence(df, group_cols):\n",
    "    for i, cols in enumerate(group_cols):\n",
    "        group_cols, col = cols[0], cols[1]\n",
    "        col_name = \"_\".join(group_cols) + '_'+col+'_mean'\n",
    "        print(i, col_name)\n",
    "        tmp = df.groupby(group_cols)[col].mean().reset_index(name=col_name)\n",
    "        df = df.merge(tmp, on=group_cols, how='left')\n",
    "        del tmp\n",
    "        gc.collect()\n",
    "    return df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ffa634944d124b43d8055ea26acc48b1173df78d9bad4819808c0946ee659080"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
