{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.datasets import load_boston,load_iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "lb = load_boston()\n",
    "features = lb.feature_names\n",
    "x_reg ,y_reg = lb.data,lb.target\n",
    "x_reg = pd.DataFrame(x_reg,columns=features)\n",
    "y_reg = pd.DataFrame(y_reg,columns=['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "li = load_iris()\n",
    "features2 = li.feature_names\n",
    "x_cls ,y_cls = li.data,li.target\n",
    "x_cls = pd.DataFrame(x_cls,columns=features2)\n",
    "y_cls = pd.DataFrame(y_cls,columns=['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
       "0  0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900  1.0  296.0   \n",
       "1  0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671  2.0  242.0   \n",
       "2  0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671  2.0  242.0   \n",
       "3  0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622  3.0  222.0   \n",
       "4  0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622  3.0  222.0   \n",
       "\n",
       "   PTRATIO       B  LSTAT  \n",
       "0     15.3  396.90   4.98  \n",
       "1     17.8  396.90   9.14  \n",
       "2     17.8  392.83   4.03  \n",
       "3     18.7  394.63   2.94  \n",
       "4     18.7  396.90   5.33  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_reg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)\n",
       "0                5.1               3.5                1.4               0.2\n",
       "1                4.9               3.0                1.4               0.2\n",
       "2                4.7               3.2                1.3               0.2\n",
       "3                4.6               3.1                1.5               0.2\n",
       "4                5.0               3.6                1.4               0.2"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_cls.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score,accuracy_score,mean_absolute_error,roc_auc_score,mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 线性回归"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "普通最小二乘的系数估计依赖于**特征的独立性**。\n",
    "\n",
    "当特征相关且设计矩阵的列之间具有**近似线性相关性**时， 设计矩阵趋于**奇异矩阵**，最小二乘估计对观测目标的随机误差高度敏感，可能产生很大的方差。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "R ^ 2定义为（1- u / v），其中u是残差平方和（（y_true-y_pred）** 2）.sum（），而v是总平方和（（y_true- y_true.mean（））** 2）.sum（）（也叫真实值的离差平方和）;\n",
    "\n",
    "[线性模型系数解释中的常见缺陷](http://scikit-learn.org.cn/view/257.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "系数：[[-1.09358524e-01  4.17604608e-02  4.92275845e-02  2.75483861e+00\n",
      "  -1.37425402e+01  4.71242684e+00 -1.19656681e-02 -1.43522444e+00\n",
      "   2.98673854e-01 -1.23637115e-02 -8.95540107e-01  1.03495304e-02\n",
      "  -5.21139480e-01]] \n",
      " 截距：[27.61502321]\n",
      "训练集的r2:0.7560832029228641\n",
      "测试集的r2:0.6225687597000795\n"
     ]
    }
   ],
   "source": [
    "X_reg_train,X_reg_test,y_reg_train,y_reg_test = train_test_split(x_reg,y_reg,random_state=2022,test_size=0.2)\n",
    "\n",
    "'''\n",
    "normalize=True , 在回归之前通过减去均值并除以l2范数来对回归变量X进行归一化；\n",
    "如果不在LinearRegression对象里调用归一化，则使用sklearn.preprocessing.StandardScaler\n",
    "'''\n",
    "reg = LinearRegression(normalize=True) \n",
    "\n",
    "# 通过 sample_weight 的平方根重新缩放数据样本\n",
    "reg.fit(X_reg_train,y_reg_train,sample_weight=0.25)\n",
    "print(f'系数：{reg.coef_} \\n 截距：{reg.intercept_}')\n",
    "print(f'训练集的r2:{reg.score(X_reg_train,y_reg_train)}')\n",
    "\n",
    "y_reg_pred = reg.predict(X_reg_test)\n",
    "print(f'测试集的r2:{r2_score(y_reg_test,y_reg_pred)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 岭回归 Ridge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "线性回归基础上 + **L2正则项**\n",
    "\n",
    "![20220706210934](https://cdn.jsdelivr.net/gh/xihuishawpy/PicBad@main/blogs/pictures/20220706210934.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "系数：[[-6.86575752e-02  1.83801716e-02 -5.51674004e-02  2.71481628e+00\n",
      "  -4.30433161e+00  4.04915189e+00 -9.39472663e-03 -4.92180619e-01\n",
      "   2.76924906e-02 -2.87975920e-03 -6.44100560e-01  7.47061607e-03\n",
      "  -3.44996611e-01]]\n",
      "训练集的r2:0.7033850851955237\n",
      "测试集的r2:0.6452418447538283\n"
     ]
    }
   ],
   "source": [
    "reg_ridge = Ridge(alpha=0.5,normalize=True) # alpha 为正则化系数，越大，则惩罚越强，w越小\n",
    "reg_ridge.fit(X_reg_train,y_reg_train)\n",
    "print(f'系数：{reg_ridge.coef_}')\n",
    "\n",
    "\n",
    "print(f'训练集的r2:{reg_ridge.score(X_reg_train,y_reg_train)}')\n",
    "\n",
    "y_reg_pred = reg_ridge.predict(X_reg_test)\n",
    "print(f'测试集的r2:{r2_score(y_reg_test,y_reg_pred)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 岭回归变种 RidgeClassifier\n",
    "\n",
    "也叫，带有线性核的最小二乘支持向量机\n",
    "\n",
    "使用Ridge回归的分类器，首先**将目标值转换为{-1, 1}**，然后将问题视为回归任务（在多类情况下为多输出回归）。\n",
    "\n",
    "**预测类对应于回归预测的符号**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集准确率:0.8583333333333333\n",
      "测试集准确率：0.9\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import RidgeClassifier\n",
    "\n",
    "X_cls_train,X_cls_test,y_cls_train,y_cls_test = train_test_split(x_cls,y_cls,random_state=2022,test_size=0.2)\n",
    "\n",
    "cls_ridge = RidgeClassifier(normalize=True)\n",
    "cls_ridge.fit(X_cls_train,y_cls_train)\n",
    "cls_ridge.coef_\n",
    "print(f'训练集准确率:{cls_ridge.score(X_cls_train,y_cls_train)}') \n",
    "\n",
    "\n",
    "y_cls_pred = cls_ridge.predict(X_cls_test)\n",
    "print(f'测试集准确率：{accuracy_score(y_cls_test,y_cls_pred)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![20220706234704](https://cdn.jsdelivr.net/gh/xihuishawpy/PicBad@main/blogs/pictures/20220706234704.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.38820477 -0.40871633 -0.97948845]]\n",
      "属于第0类\n"
     ]
    }
   ],
   "source": [
    "# 预测样本的置信度分数\n",
    "# 样本的置信度分数与该样本到超平面的有符号距离成正比\n",
    "confidence_score = cls_ridge.decision_function([[4.5,3.1,2.0,0.35]])\n",
    "print(confidence_score)\n",
    "\n",
    "print(f'属于第{np.argmax(confidence_score)}类')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RidgeCV "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RidgeCV 通过内置的alpha 参数的控制交叉验证来实现岭回归。 \n",
    "\n",
    "该对象与 GridSearchCV 的使用方法相同，如果不指定cv（cv=None），默认为留一交叉验证方法（LOO-CV，即抽取一个样本作为测试集数据）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "最佳alpha取值：1.0\n",
      "训练集的r2:0.7547330246063915\n",
      "测试集的r2:0.6120292876368366\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import RidgeCV\n",
    "\n",
    "reg_ridgecv = RidgeCV(alphas=np.logspace(-6,6,13),cv=10) \n",
    "reg_ridgecv.fit(X_reg_train,y_reg_train)\n",
    "print(f'最佳alpha取值：{reg_ridgecv.alpha_}')\n",
    "reg_ridgecv.coef_\n",
    "\n",
    "\n",
    "print(f'训练集的r2:{reg_ridgecv.score(X_reg_train,y_reg_train)}')\n",
    "\n",
    "y_reg_pred = reg_ridgecv.predict(X_reg_test)\n",
    "print(f'测试集的r2:{r2_score(y_reg_test,y_reg_pred)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lasso"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lasso是一个估计稀疏系数的线性模型。它在某些情况下是有用的，因为它倾向于给出非零系数较少的解，从而有效地减少了给定解所依赖的特征数。\n",
    "\n",
    "线性回归 + L1正则项\n",
    "\n",
    "![20220707002437](https://cdn.jsdelivr.net/gh/xihuishawpy/PicBad@main/blogs/pictures/20220707002437.png)\n",
    "\n",
    "Lasso产生稀疏矩阵，可用来作特征选择，alpha参数越高，所选择的特征就越少。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "系数：[-0.06458  0.04446 -0.       0.      -0.       1.13055  0.02012 -0.71969\n",
      "  0.27929 -0.01466 -0.7708   0.00871 -0.80275] \n",
      " 截距：[41.15011875]\n",
      "训练集的r2:0.7560832029228641\n",
      "测试集的r2:0.6460796009959273\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import  Lasso, LassoCV\n",
    "\n",
    "reg_lasso = Lasso(alpha=1.1)\n",
    "reg_lasso.fit(X_reg_train,y_reg_train)\n",
    "\n",
    "print(f'系数：{np.round(reg_lasso.coef_,5)} \\n 截距：{reg_lasso.intercept_}')\n",
    "print(f'训练集的r2:{reg.score(X_reg_train,y_reg_train)}')\n",
    "\n",
    "y_reg_pred = reg_lasso.predict(X_reg_test)\n",
    "print(f'测试集的r2:{r2_score(y_reg_test,y_reg_pred)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "最佳alpha：0.0\n",
      "系数：[-1.093600e-01  4.176000e-02  4.923000e-02  2.754840e+00 -1.374254e+01\n",
      "  4.712430e+00 -1.197000e-02 -1.435220e+00  2.986700e-01 -1.236000e-02\n",
      " -8.955400e-01  1.035000e-02 -5.211400e-01] \n",
      " 截距：27.615023209546624\n",
      "训练集score：0.7560832029228641\n",
      "测试集score：0.6225687597000796\n"
     ]
    }
   ],
   "source": [
    "reg_lassocv = LassoCV(cv=5,random_state=2022,alphas=np.arange(0,2,0.01))\n",
    "reg_lassocv.fit(X_reg_train,y_reg_train)\n",
    "print(f'最佳alpha：{reg_lassocv.alpha_}')\n",
    "\n",
    "print(f'系数：{np.round(reg_lassocv.coef_,5)} \\n 截距：{reg_lassocv.intercept_}')\n",
    "print(f'训练集score：{reg_lassocv.score(X_reg_train,y_reg_train)}')\n",
    "\n",
    "y_reg_pred = reg_lassocv.predict(X_reg_test)\n",
    "print(f'测试集score：{r2_score(y_reg_test,y_reg_pred)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 弹性网络 -- ElasticNet "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "通过调整**l1_ratio**，调整L1\\L2的组合\n",
    "\n",
    "![20220707101826](https://cdn.jsdelivr.net/gh/xihuishawpy/PicBad@main/blogs/pictures/20220707101826.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "系数：[-0.09379  0.05137 -0.       0.      -0.       2.01367  0.00582 -1.05469\n",
      "  0.33827 -0.01671 -0.85229  0.0097  -0.7472 ] \n",
      " 截距：[38.58675094]\n",
      "训练集r2：0.7200146013972221\n",
      "测试集r2:0.6388913772483735\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import ElasticNet\n",
    "\n",
    "reg_elsnet = ElasticNet(alpha=0.5,l1_ratio=0.5)\n",
    "reg_elsnet.fit(X_reg_train,y_reg_train)\n",
    "\n",
    "print(f'系数：{np.round(reg_elsnet.coef_,5)} \\n 截距：{reg_elsnet.intercept_}')\n",
    "print(f'训练集r2：{reg_elsnet.score(X_reg_train,y_reg_train)}')\n",
    "\n",
    "y_reg_pred = reg_elsnet.predict(X_reg_test)\n",
    "print(f'测试集r2:{r2_score(y_reg_test,y_reg_pred)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 最小角回归 -- Least-angle regression， LARS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "用于高维数据的回归算法。\n",
    "\n",
    "LARs和逐步向前回归很相似。在每一步中，它都会找到与目标最相关的特征。当多个特征具有相等的相关性时，它不是沿着相同的特征继续进行，而是沿着特征之间等角的方向进行。\n",
    "\n",
    "![20220707110207](https://cdn.jsdelivr.net/gh/xihuishawpy/PicBad@main/blogs/pictures/20220707110207.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.0582612   0.01447872  0.          2.54782975 -7.4947512   5.06727161\n",
      "  0.         -0.81838349  0.01354248  0.         -0.79341687  0.00801916\n",
      " -0.52311074]\n",
      "训练集r2:0.7560832029228641\n",
      "测试集r2:0.6069215238656641\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Lars\n",
    "\n",
    "# n_nonzero_coefs , 非0系数的数量\n",
    "reg_lars = Lars(n_nonzero_coefs=10)\n",
    "reg_lars.fit(X_reg_train,y_reg_train)\n",
    "print(reg_lars.coef_ )\n",
    "print(f'训练集r2:{reg.score(X_reg_train,y_reg_train)}')\n",
    "\n",
    "y_reg_pred = reg_lars.predict(X_reg_test)\n",
    "print(f'测试集r2:{r2_score(y_reg_test,y_reg_pred)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 贝叶斯回归"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "贝叶斯回归技术可以用于**预估正则化参数**：\n",
    "\n",
    "正则化参数不是在硬意义上设置，而是根据手头的数据进行调整。(通过在模型的超参数上引入信息不足的先验（uninformative priors）来实现。)\n",
    "\n",
    "\n",
    "贝叶斯回归的优点是：\n",
    "\n",
    "- 它可以调整以适应手头的数据\n",
    "- 它可以用于在估计过程中引入正则项。\n",
    "\n",
    "贝叶斯回归的缺点包括：\n",
    "- 模型的推断可能很费时间。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.04920198e-01  4.58620000e-02  8.24472523e-04  1.93876881e+00\n",
      " -1.68585850e+00  4.40793413e+00 -1.83356680e-02 -1.26773465e+00\n",
      "  2.89327632e-01 -1.40982365e-02 -7.97718311e-01  1.07600296e-02\n",
      " -5.71063634e-01]\n",
      "0.7499565296829631\n"
     ]
    }
   ],
   "source": [
    "# 贝叶斯岭回归\n",
    "from sklearn.linear_model import BayesianRidge\n",
    "\n",
    "reg_bayesridge = BayesianRidge()\n",
    "reg_bayesridge.fit(X_reg_train,y_reg_train)\n",
    "print(reg_bayesridge.coef_)\n",
    "\n",
    "print(reg_bayesridge.score(X_reg_train,y_reg_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic回归"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![20220707132351](https://cdn.jsdelivr.net/gh/xihuishawpy/PicBad@main/blogs/pictures/20220707132351.png)\n",
    "\n",
    "“lbfgs”鲁棒性更强， 默认是“lbfgs”。\n",
    "\n",
    "对于大型数据集，“saga”通常更快。对于大型数据集，还可考虑使用对数损失( ‘log’ loss)的 SGDClassifier，这可能会更快，但需要更多的调优。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "决策函数特征系数:\n",
      "[[ 0.          2.17392719 -2.46070693  0.        ]\n",
      " [ 0.39416871 -1.25458345  0.56418343 -1.09830101]\n",
      " [-1.66201155 -2.23765367  1.85357187  4.59524288]]\n",
      "训练集准确度：0.975\n",
      "测试集准确率：0.9\n",
      "2\n",
      "2\n",
      "0\n",
      "2\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# C值为正则强度的倒数 \n",
    "# 所以，较大的C值给了模型更多的自由度。相反，较小的C值指定更强的正则化\n",
    "cls_lr = LogisticRegression(penalty='l1',tol=1e-6,solver='liblinear',C=0.7)\n",
    "# cls_lr = LogisticRegression(l1_ratio=1,tol=1e-6,solver='liblinear',C=0.7) # 二者等价；l1_ratio=0，则是penalty='l2'\n",
    "cls_lr.fit(X_cls_train,y_cls_train)\n",
    "\n",
    "print(f'决策函数特征系数:\\n{cls_lr.coef_}')\n",
    "print(f'训练集准确度：{cls_lr.score(X_cls_train,y_cls_train)}')\n",
    "\n",
    "# 预测类别标签\n",
    "y_cls_pred = cls_lr.predict(X_cls_test)\n",
    "print(f'测试集准确率：{accuracy_score(y_cls_test,y_cls_pred)}')\n",
    "\n",
    "# 预测每个样本属于每类的概率估计\n",
    "for i in cls_lr.predict_proba(X_cls_test)[:5]:\n",
    "    print(np.argmax(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 0, 2, 0])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_cls_pred[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 随机梯度下降-- SGD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "严格地说，SGD只是一种优化技术，并不与特定的机器学习模型相对应。它只是**训练模型的一种方式**；\n",
    "\n",
    "例如，使用`SGDClassifier(loss='log')`将导致Logistic回归， 即`等价于LogisticRegression的模型可以通过SGD拟合`，而不是LogisticRegression中其他的优化方案。\n",
    "\n",
    "SGDRegressor(loss='squared_loss', penalty='l2')和 Ridge就是通过不同的方法解决了相同的优化问题。\n",
    "\n",
    "- 优点：实现简单、速度贼快；\n",
    "- 缺点：**对特征值的量纲贼敏感，一定要提前进行特征缩放**，不然梯度下降成“Z”字型，瞎晃~~~（相同的缩放必须应用于测试向量以获得有意义的结果）\n",
    "\n",
    "`在拟合模型之前，一定要重新排序(打乱的)训练数据，或者在每次迭代后(默认情况下使用)使用shuffle=True来打乱数据`\n",
    "\n",
    "分类：\n",
    "\n",
    "![20220707142556](https://cdn.jsdelivr.net/gh/xihuishawpy/PicBad@main/blogs/pictures/20220707142556.png)\n",
    "\n",
    "回归：\n",
    "\n",
    "![20220707142703](https://cdn.jsdelivr.net/gh/xihuishawpy/PicBad@main/blogs/pictures/20220707142703.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集准确率：0.975\n",
      "测试集准确率：0.9333333333333333\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1.67330241e-36, 3.21921928e-01, 6.78078072e-01],\n",
       "       [2.71639726e-50, 4.60960723e-01, 5.39039277e-01],\n",
       "       [7.92078088e-01, 2.07921912e-01, 9.92394448e-60],\n",
       "       [2.47199837e-31, 4.04092318e-01, 5.95907682e-01],\n",
       "       [9.77401844e-01, 2.25981563e-02, 1.37137866e-63]])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# 特征缩放\n",
    "scaler = StandardScaler()\n",
    "x_cls_scale = scaler.fit_transform(li.data) \n",
    "\n",
    "x_cls_trn_scale , x_cls_test_scale , y_cls_train,y_cls_test = train_test_split(x_cls_scale,y_cls,random_state=2022,test_size=0.2)\n",
    "\n",
    "# SGD版本的LR\n",
    "sgdcls = SGDClassifier(loss='log',penalty='l1',l1_ratio=0.5,shuffle=True)\n",
    "sgdcls.fit(x_cls_trn_scale,y_cls_train)\n",
    "print(f'训练集准确率：{sgdcls.score(x_cls_trn_scale,y_cls_train)}')\n",
    "\n",
    "y_cls_pred = sgdcls.predict(x_cls_test_scale)\n",
    "print(f'测试集准确率：{accuracy_score(y_cls_test,y_cls_pred)}')\n",
    "\n",
    "sgdcls.predict_proba(x_cls_test_scale)[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "附：\n",
    "\n",
    "![20220707143203](https://cdn.jsdelivr.net/gh/xihuishawpy/PicBad@main/blogs/pictures/20220707143203.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ffa634944d124b43d8055ea26acc48b1173df78d9bad4819808c0946ee659080"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
