{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_path ='./dataset/train.csv'\n",
    "train = pd.read_csv(train_data_path)\n",
    "\n",
    "test_data_path ='./dataset/test.csv'\n",
    "test = pd.read_csv(test_data_path)\n",
    "\n",
    "num_of_train_data = train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ceallach_Shaw\\AppData\\Local\\Temp\\ipykernel_21240\\4137068044.py:8: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  combined = train.append(test)\n"
     ]
    }
   ],
   "source": [
    "# 房价，要拟合的目标值\n",
    "target = train.SalePrice\n",
    "\n",
    "# 输入特征，可以将SalePrice列扔掉\n",
    "train.drop(['SalePrice'],axis = 1 , inplace = True)\n",
    "\n",
    "# 将train和test合并到一起，一块进行特征工程，方便预测test的房价\n",
    "combined = train.append(test)\n",
    "combined.reset_index(inplace=True)\n",
    "combined.drop(['index', 'Id'], inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 选出非空列\n",
    "def get_cols_with_no_nans(df,col_type):\n",
    "    '''\n",
    "    Arguments :\n",
    "    df : The dataframe to process\n",
    "    col_type : \n",
    "          num : to only get numerical columns with no nans\n",
    "          no_num : to only get nun-numerical columns with no nans\n",
    "          all : to get any columns with no nans    \n",
    "    '''\n",
    "    if (col_type == 'num'):\n",
    "        predictors = df.select_dtypes(exclude=['object'])\n",
    "    elif (col_type == 'no_num'):\n",
    "        predictors = df.select_dtypes(include=['object'])\n",
    "    elif (col_type == 'all'):\n",
    "        predictors = df\n",
    "    else :\n",
    "        print('Error : choose a type (num, no_num, all)')\n",
    "        return 0\n",
    "    cols_with_no_nans = []\n",
    "    for col in predictors.columns:\n",
    "        if not df[col].isnull().any():\n",
    "            cols_with_no_nans.append(col)\n",
    "    return cols_with_no_nans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['MSSubClass', 'LotArea', 'OverallQual', 'OverallCond', 'YearBuilt']\n",
      "Number of numerical columns with no nan values:  25\n",
      "['Street', 'LotShape', 'LandContour', 'LotConfig', 'LandSlope']\n",
      "Number of non-numerical columns with no nan values:  20\n"
     ]
    }
   ],
   "source": [
    "num_cols = get_cols_with_no_nans(combined, 'num')\n",
    "cat_cols = get_cols_with_no_nans(combined, 'no_num')\n",
    "\n",
    "# 过滤掉含有缺失值的特征\n",
    "combined = combined[num_cols + cat_cols]\n",
    "\n",
    "print(num_cols[:5])\n",
    "print ('Number of numerical columns with no nan values: ',len(num_cols))\n",
    "print(cat_cols[:5])\n",
    "print ('Number of non-numerical columns with no nan values: ',len(cat_cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 对分类特征进行One-Hot编码\n",
    "def oneHotEncode(df,colNames):\n",
    "    for col in colNames:\n",
    "        if( df[col].dtype == np.dtype('object')):\n",
    "            # pandas.get_dummies 可以对分类特征进行One-Hot编码\n",
    "            dummies = pd.get_dummies(df[col],prefix=col)\n",
    "            df = pd.concat([df,dummies],axis=1)\n",
    "\n",
    "            # drop the encoded column\n",
    "            df.drop([col],axis = 1 , inplace=True)\n",
    "    return df\n",
    "\n",
    "\n",
    "combined = oneHotEncode(combined,cat_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data size:  torch.Size([1460, 149])\n",
      "label data size:  torch.Size([1460, 1])\n",
      "test data size:  torch.Size([1459, 149])\n"
     ]
    }
   ],
   "source": [
    "# 训练数据集特征\n",
    "train_features = torch.tensor(combined[:num_of_train_data].values, dtype=torch.float)\n",
    "# 训练数据集目标\n",
    "train_labels = torch.tensor(target.values, dtype=torch.float).view(-1, 1)\n",
    "# 测试数据集特征\n",
    "test_features = torch.tensor(combined[num_of_train_data:].values, dtype=torch.float)\n",
    "\n",
    "print(\"train data size: \", train_features.shape)\n",
    "print(\"label data size: \", train_labels.shape)\n",
    "print(\"test data size: \", test_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 搭积木式 构建\n",
    "model_sequential = nn.Sequential(\n",
    "          nn.Linear(train_features.shape[1], 128),\n",
    "          nn.ReLU(),\n",
    "          nn.Linear(128, 256),\n",
    "          nn.ReLU(),\n",
    "          nn.Linear(256, 256),\n",
    "          nn.ReLU(),\n",
    "          nn.Linear(256, 256),\n",
    "          nn.ReLU(),\n",
    "          nn.Linear(256, 1)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "      \n",
    "    def __init__(self, features):\n",
    "        super(Net, self).__init__()\n",
    "    # 定义网络结构\n",
    "        self.linear_relu1 = nn.Linear(features, 128)\n",
    "        self.linear_relu2 = nn.Linear(128, 256)\n",
    "        self.linear_relu3 = nn.Linear(256, 256)\n",
    "        self.linear_relu4 = nn.Linear(256, 256)\n",
    "        self.linear5 = nn.Linear(256, 1)\n",
    "    \n",
    "    # 前向传播    \n",
    "    def forward(self, x):\n",
    "        \n",
    "        y_pred = self.linear_relu1(x)\n",
    "        y_pred = nn.functional.relu(y_pred)\n",
    "\n",
    "        y_pred = self.linear_relu2(y_pred)\n",
    "        y_pred = nn.functional.relu(y_pred)\n",
    "\n",
    "        y_pred = self.linear_relu3(y_pred)\n",
    "        y_pred = nn.functional.relu(y_pred)\n",
    "\n",
    "        y_pred = self.linear_relu4(y_pred)\n",
    "        y_pred = nn.functional.relu(y_pred)\n",
    "\n",
    "        y_pred = self.linear5(y_pred)\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 初始化模型对象\n",
    "model = Net(features=train_features.shape[1])\n",
    "\n",
    "# 使用均方误差作为损失函数\n",
    "criterion = nn.MSELoss(reduction='mean')\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = []\n",
    "\n",
    "# 训练500轮\n",
    "for _ in range(500):\n",
    "    # 每次迭代使用训练数据集中的所有样本 train_features\n",
    "    y_pred = model(train_features)\n",
    "\n",
    "    loss = criterion(y_pred, train_labels)\n",
    "    # print(t, loss.item())\n",
    "    losses.append(loss.item())\n",
    "\n",
    "    if torch.isnan(loss):\n",
    "        break\n",
    "\n",
    "    # 将模型中各参数的梯度清零。\n",
    "    # PyTorch的backward()方法计算梯度会默认将本次计算的梯度与缓存中已有的梯度加和。\n",
    "    # 必须在反向传播前先清零。\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # 反向传播，计算各参数对于损失loss的梯度\n",
    "    loss.backward()\n",
    "\n",
    "    # 根据刚刚反向传播得到的梯度更新模型参数\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model(test_features).detach().numpy()\n",
    "my_submission = pd.DataFrame({'Id':pd.read_csv('./dataset/test.csv').Id,'SalePrice': predictions[:, 0]})\n",
    "my_submission.to_csv('./dataset/submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "add722709fbf584f8089b6292d79f8f1a2f576fcf9989ad3231b19d6340d13bf"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
